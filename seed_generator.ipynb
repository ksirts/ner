{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Genernator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "def seed_generator() -> list:\n",
    "    seed_lst = []\n",
    "    for i in range(0, 11):\n",
    "        ct = datetime.datetime.now()\n",
    "        random.seed(a=ct.timestamp(), version=2)\n",
    "        seed_lst.append('{0:04d}'.format(int(random.random()*10000)))\n",
    "\n",
    "    return seed_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config File Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config text\n",
    "\n",
    "def config_generator(*argv) -> str:\n",
    "    seed_lst = argv[0]\n",
    "    for seed in seed_lst:\n",
    "        config_str = '''\n",
    "        {\n",
    "        \"model_name_or_path\": \"tartuNLP/EstBERT\",\n",
    "        \"cache_dir\": \"/gpfs/space/home/chenghan/ner/models\",\n",
    "        \"dataset_name\": \"estner\",\n",
    "        \"max_seq_length\": 128,\n",
    "        \"do_train\": \"True\",\n",
    "        \"do_eval\": \"True\",\n",
    "        \"do_predict\": \"True\",\n",
    "        \"output_dir\": \"/gpfs/space/home/chenghan/ner/output/new_ner/lr3e5s{0}\",\n",
    "        \"overwrite_output_dir\": \"True\",\n",
    "        \"report_to\": \"wandb\",\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"per_device_train_batch_size\": 16,\n",
    "        \"per_device_eval_batch_size\": 16,\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"adam_beta1\": 0.9,\n",
    "        \"adam_beta2\": 0.98,\n",
    "        \"adam_epsilon\": 1e-6,\n",
    "        \"num_train_epochs\": 150,\n",
    "        \"lr_scheduler_type\": \"polynomial\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"logging_first_step\": \"True\",\n",
    "        \"logging_steps\": 150,\n",
    "        \"save_strategy\": \"epoch\",\n",
    "        \"seed\": {1},\n",
    "        \"fp16\": \"True\",\n",
    "        \"fp16_full_eval\": \"False\",\n",
    "        \"run_name\": \"ner_estbert_new_b16_lr3e-5_s{2}\",\n",
    "        \"load_best_model_at_end\": \"True\",\n",
    "        \"metric_for_best_model\": \"eval_f1\",\n",
    "        \"return_tag_level_metrics\": \"False\",\n",
    "        \"save_total_limit\": 3\n",
    "        }'''.format(seed,seed,seed)\n",
    "    return config_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Modify token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "_PATH = r'./data/EstNER_token'\n",
    "file_list = {'EstNER_token_test.json',\n",
    "             'EstNER_token_dev.json', 'EstNER_token_train.json'}\n",
    "entity_list = {'PER', 'GPE', 'LOC', 'ORG'}\n",
    "cnt=0\n",
    "for jf in file_list:\n",
    "    with open(f'{_PATH}/{jf}', 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        for doc in data['documents']:\n",
    "            for sent in doc['sentences']:\n",
    "                for word in sent['words']:\n",
    "                    if (any(map(word['ner_1'].__contains__, entity_list))):\n",
    "                        pass\n",
    "                    else:\n",
    "                        word['ner_1'] = \"O\" # trandfer entities to un-labled\n",
    "\n",
    "        f.seek(0)  # rewind\n",
    "        json.dump(data, f)\n",
    "        f.truncate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"d3auuv/huggingface\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k, v in run.config.items()\n",
    "         if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "})\n",
    "\n",
    "_JSON_FILE_NAME = 'project.json'\n",
    "runs_df.to_json(_JSON_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "eval/TITLE_precision 0.7777777778\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_f1 0.7368421053\n",
      "eval/TITLE_recall 0.7\n",
      "6891\n",
      "eval/TITLE_recall 0.75\n",
      "eval/TITLE_f1 0.7692307692\n",
      "eval/TITLE_precision 0.7894736842\n",
      "eval/TITLE_number 20\n",
      "9470\n",
      "eval/TITLE_precision 0.7777777778\n",
      "eval/TITLE_f1 0.7368421053\n",
      "eval/TITLE_recall 0.7\n",
      "eval/TITLE_number 20\n",
      "6523\n",
      "eval/TITLE_recall 0.8\n",
      "eval/TITLE_f1 0.7441860465\n",
      "eval/TITLE_precision 0.6956521739\n",
      "eval/TITLE_number 20\n",
      "6730\n",
      "eval/TITLE_f1 0.7567567568\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_recall 0.7\n",
      "eval/TITLE_precision 0.8235294118\n",
      "5490\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_recall 0.7\n",
      "eval/TITLE_f1 0.7\n",
      "eval/TITLE_precision 0.7\n",
      "3552\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_recall 0.7\n",
      "eval/TITLE_precision 0.7368421053\n",
      "eval/TITLE_f1 0.7179487179\n",
      "4378\n",
      "eval/TITLE_f1 0.6666666667\n",
      "eval/TITLE_recall 0.65\n",
      "eval/TITLE_precision 0.6842105263\n",
      "eval/TITLE_number 20\n",
      "5436\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_recall 0.7\n",
      "eval/TITLE_f1 0.7368421053\n",
      "eval/TITLE_precision 0.7777777778\n",
      "1024\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_precision 0.7368421053\n",
      "eval/TITLE_recall 0.7\n",
      "eval/TITLE_f1 0.7179487179\n",
      "5974\n",
      "eval/TITLE_precision 0.6842105263\n",
      "eval/TITLE_recall 0.65\n",
      "eval/TITLE_number 20\n",
      "eval/TITLE_f1 0.6666666667\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openpyxl import workbook,load_workbook\n",
    "\n",
    "ent_lst=['PER','GPE','LOC','ORG','PROD','EVENT','DATE','TIME','TITLE','MONEY','PERCENT']\n",
    "score_lst=['f1','recall','precision']\n",
    "with open(_JSON_FILE_NAME, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i in range(11):\n",
    "    sum = data['summary']\n",
    "    model = sum[str(i)]\n",
    "    print(data['config'][str(i)]['seed'])\n",
    "    for key,value in model.items():\n",
    "        if key.find(f'eval/TITLE') != -1:\n",
    "            print(key,value)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
